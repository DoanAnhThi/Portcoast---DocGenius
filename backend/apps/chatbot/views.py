from django.shortcuts import render
from django.core.files.storage import FileSystemStorage
from django.http import JsonResponse, HttpResponse
from django.views.decorators.csrf import csrf_exempt
import json
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from langchain_community.llms import HuggingFacePipeline
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

# üè∑Ô∏è 1Ô∏è‚É£ **Ch·ªçn m√¥ h√¨nh DeepSeek t·ª´ Hugging Face**
MODEL_NAME = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"  # ƒê·ªïi t√™n m√¥ h√¨nh n·∫øu c·∫ßn
print("üîÑ ƒêang t·∫£i m√¥ h√¨nh:", MODEL_NAME)

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, device_map="auto")
    print("‚úÖ M√¥ h√¨nh t·∫£i th√†nh c√¥ng!")
except Exception as e:
    print("‚ùå L·ªói khi t·∫£i m√¥ h√¨nh:", e)

# üè∑Ô∏è 2Ô∏è‚É£ **T·∫°o pipeline x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n**
# text_pipeline = pipeline(
#     "text-generation", model=model, tokenizer=tokenizer, 
#     max_new_tokens=200, do_sample=True, temperature=0.7
# )
text_pipeline = pipeline(
    "text-generation", 
    model=model, 
    tokenizer=tokenizer, 
    max_new_tokens=100,  # Gi·ªõi h·∫°n s·ªë token ƒë·∫ßu ra
    do_sample=True, 
    temperature=0.7,
    top_k=50,  # Gi·∫£m m·ª©c ƒë·ªô "h√†nh vƒÉn l·∫∑p l·∫°i"
    top_p=0.9  # Gi√∫p m√¥ h√¨nh t·∫°o ra ph·∫£n h·ªìi t·ª± nhi√™n h∆°n
)

llm = HuggingFacePipeline(pipeline=text_pipeline)

# üè∑Ô∏è 3Ô∏è‚É£ **Thi·∫øt l·∫≠p b·ªô nh·ªõ h·ªôi tho·∫°i**
memory = ConversationBufferMemory()
conversation = ConversationChain(llm=llm, memory=memory)

# üè∑Ô∏è 4Ô∏è‚É£ **H√†m x·ª≠ l√Ω h·ªôi tho·∫°i**
# def chatbot_response(user_input):
#     response = conversation.invoke(user_input)  # S·ª≠ d·ª•ng .invoke() thay v√¨ .run()
#     return response
def chatbot_response(user_input):
    response = text_pipeline(user_input, max_new_tokens=100)[0]["generated_text"]
    
    # üõ† X√≥a ph·∫ßn n·ªôi dung prompt m·∫∑c ƒë·ªãnh n·∫øu c√≥
    if "Current conversation" in response:
        response = response.split("Current conversation:")[-1].strip()

    return response


# ‚úÖ **API ch√≠nh**
@csrf_exempt  # Lo·∫°i b·ªè ki·ªÉm tra CSRF ƒë·ªÉ d·ªÖ test
def chatbot_api(request):
    if request.method == "POST":
        try:
            data = json.loads(request.body)
            user_message = data.get("message", "")

            if not user_message:
                return JsonResponse({"error": "Message cannot be empty"}, status=400)

            bot_response = chatbot_response(user_message)  # G·ªçi m√¥ h√¨nh LLM ƒë·ªÉ tr·∫£ l·ªùi

            return JsonResponse({"reply": bot_response})
        except Exception as e:
            return JsonResponse({"error": str(e)}, status=500)

    return JsonResponse({"error": "Invalid request"}, status=400)

# ‚úÖ **Giao di·ªán chatbot**
def chatbot_view(request):
    return render(request, "chatbot/chatbot.html")

# ‚úÖ **Upload t√†i li·ªáu**
def upload_document(request):
    if request.method == "POST" and request.FILES.get("document"):
        file = request.FILES["document"]
        fs = FileSystemStorage()
        fs.save(file.name, file)
        return render(request, "chatbot/chatbot.html", {"message": "T·∫£i t√†i li·ªáu th√†nh c√¥ng!"})
    return render(request, "chatbot/chatbot.html")

# ‚úÖ **Test ch·∫°y m√¥ h√¨nh b·∫±ng Terminal**
if __name__ == "__main__":
    while True:
        user_input = input("You: ")
        if user_input.lower() == "exit":
            break
        response = chatbot_response(user_input)
        print(f"Bot: {response}")
